{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sagemaker\n",
      "Version: 2.232.2\n",
      "Summary: Open source library for training and deploying models on Amazon SageMaker.\n",
      "Home-page: https://github.com/aws/sagemaker-python-sdk\n",
      "Author: Amazon Web Services\n",
      "Author-email: \n",
      "License: \n",
      "Location: c:\\Users\\shefa\\Documents\\GitHub\\Advanced-Classification-for-Imbalanced-Data\\venv_aws\\Lib\\site-packages\n",
      "Requires: attrs, boto3, cloudpickle, docker, google-pasta, importlib-metadata, jsonschema, numpy, packaging, pandas, pathos, platformdirs, protobuf, psutil, pyyaml, requests, sagemaker-core, sagemaker-mlflow, schema, smdebug-rulesconfig, tblib, tqdm, urllib3\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# Check if sagemaker is installed using pip\n",
    "!pip show sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "import sys\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.session.Session()\n",
    "region = session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "pipeline_session = PipelineSession()\n",
    "# Setbucket to \"s3://amazon-product-dataset-2024\"\n",
    "bucket = \"s3://amazon-product-dataset-2024\"\n",
    "model_package_group_name = f\"MLImbalancedClassificationAmazonDataset-{region}\"\n",
    "prefix = \"processing-artifacts\"  # Prefix for S3 bucket to store data\n",
    "\n",
    "# bucket = session.default_bucket() # You can replace with your own bucket name if you have one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")\n",
    "\n",
    "model_registry_package = ParameterString(name=\"ComparativeMLModelGroup\", default_value=\"default-registry\") # Name of the model registry\n",
    "\n",
    "# Data parameters\n",
    "input_data = ParameterString(name=\"InputData\", default_value=\"s3://{}/transformed/transformed-data.parquet\".format(bucket)) # S3 URI to input data\n",
    "\n",
    "# Scripts parameters for preprocessing, training and evaluation\n",
    "preprocessing_script = ParameterString(name=\"PreprocessScript\", default_value=\"s3://{}/scripts/preprocess/preprocess.py\".format(bucket))\n",
    " # Name of the preprocessing script\n",
    " \n",
    "# training_script = ParameterString(name=\"TrainingScript\", default_value=\"s3://{}/scripts/xgboost/train.py\".format(bucket)) # Name of the training and hyperparameter tuning script. but trainingstep in sagemaker does not allow for a script to be passed in as a parameter, so we will not use this parameter.\n",
    "\n",
    "evaluation_script = ParameterString(name=\"EvaluationScript\", default_value=\"s3://{}/scripts/xgboost/evaluate.py\".format(bucket)) # Name of the evaluation script\n",
    "\n",
    "################ WE WILL NEED TO CHANGE THIS FOR EACH MODEL PIPELINE ################\n",
    "\n",
    "# Hyperparameters for XGBoost\n",
    "max_depth = ParameterInteger(name=\"MaxDepth\", default_value=5) # Maximum depth of the tree\n",
    "eta = ParameterFloat(name=\"Eta\", default_value=0.2) # Step size shrinkage used in updates to prevent overfitting\n",
    "gamma = ParameterFloat(name=\"Gamma\", default_value=4) # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "min_child_weight = ParameterInteger(name=\"MinChildWeight\", default_value=6) # Minimum sum of instance weight (hessian) needed in a child\n",
    "subsample = ParameterFloat(name=\"Subsample\", default_value=0.8) # Subsample ratio of the training instances\n",
    "num_round = ParameterInteger(name=\"NumRound\", default_value=100) # Number of rounds for boosting\n",
    "objective = ParameterString(name=\"Objective\", default_value=\"binary:logistic\") # Specify the learning task and the corresponding learning objective\n",
    "eval_metric = ParameterString(name=\"EvalMetric\", default_value=\"auc\") # Evaluation metrics for validation data\n",
    "early_stopping_rounds = ParameterInteger(name=\"EarlyStoppingRounds\", default_value=10) # Activates early stopping. Validation metric needs to improve at least once in every early_stopping_rounds round(s) to continue training\n",
    "scale_pos_weight = ParameterFloat(name=\"ScalePosWeight\", default_value=1) # Control the balance of positive and negative weights, useful for unbalanced classes # sqrt(count(negative examples)/count(Positive examples)) = sqrt # 1364475/8112 = 21.5. Source: https://stats.stackexchange.com/questions/243207/what-is-the-proper-usage-of-scale-pos-weight-in-xgboost-for-imbalanced-datasets\n",
    "\n",
    "\n",
    "\n",
    "# Resource parameters\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1) # instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "processing_instance_type = ParameterString(name=\"ProcessingInstanceType\", default_value=\"ml.m5.large\") # processing instance type\n",
    "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\") # training instance type (optimized for training)\n",
    "max_training_jobs = ParameterInteger(name=\"MaxiumTrainingJobs\", default_value=1) # max. number of training jobs\n",
    "# Maximum amount of trainingjobs to allow in the HP tuning\n",
    "max_parallel_training_jobs = ParameterInteger(name=\"MaxiumParallelTrainingJobs\", default_value=1) # max. number of parallel training jobs\n",
    "\n",
    "# Accuracy threshold to decide whether or not to register the model with Model Registry\n",
    "# accuracy_condition_threshold = ParameterFloat(name=\"AccuracyConditionThreshold\", default_value=0.7) # Accuracy threshold to decide whether or not to register the model with Model Registry. Not relevant for comparative models as we will register all models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProcessingStep\n",
    "\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"1.2-1\",\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-abalone-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_args = sklearn_processor.run(\n",
    "    inputs = [\n",
    "        ProcessingInput(source=input_data, \n",
    "                        destination=\"/opt/ml/processing/input\")\n",
    "                        ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/train\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"train\",\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            source=\"/opt/ml/processing/validation\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"validation\",\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/test\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"test\",\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "code = preprocessing_script, # this is the preprocessing script\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(name=\"Prepare-Data\",display_name='Preprocessing',\n",
    "                              step_args=processor_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and tuning step\n",
    "\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.tuner import HyperparameterTuner, ContinuousParameter, IntegerParameter\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.0-1\",# check latest version\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "\n",
    "xgb_estimator = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    disable_profiler=True,\n",
    ")\n",
    "\n",
    "\n",
    "xgb_tuner = HyperparameterTuner(\n",
    "    estimator=xgb_estimator,\n",
    "    objective_metric_name=\"validation:aucpr\", # we will use the AUCPR as the metric to optimize as we have extremely imbalanced classes\n",
    "    hyperparameter_ranges={ ##  TO BE EDITED!! ##\n",
    "        \"eta\": ContinuousParameter(0, 0.5),\n",
    "        \"alpha\": ContinuousParameter(0, 1000),\n",
    "        \"min_child_weight\": ContinuousParameter(1, 120),\n",
    "        \"max_depth\": IntegerParameter(1, 10),\n",
    "        \"num_round\": IntegerParameter(1, 2000),\n",
    "        \"subsample\": ContinuousParameter(0.5, 1),\n",
    "        \"scale_pos_weight\": ContinuousParameter(15, 50),\n",
    "    },\n",
    "    max_jobs=max_training_jobs, # max. number of training jobs to run\n",
    "    max_parallel_jobs=max_parallel_training_jobs,\n",
    "    strategy=\"Bayesian\",\n",
    "    early_stopping_type=\"Auto\",\n",
    "\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_tuning = TuningStep(\n",
    "    name=\"Train-And-Tune-Model\",\n",
    "    display_name=\"Train-And-Tune-Model\",\n",
    "    tuner=xgb_tuner,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate step\n",
    "\n",
    "# Create SKLearn Processor to evaluate model\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "evaluate_model_processor = ScriptProcessor(\n",
    "    image_uri=sklearn_processor_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    base_job_name=f\"{base_job_prefix}/evaluation\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "# Script that will be used for model evaluation\n",
    "evaluate_script = ScriptProcessor.run.__defaults__[0]  \n",
    "\n",
    "# Create property file to store evaluation metrics\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    balanced_accuracy_score\n",
    ")\n",
    "\n",
    "\n",
    "model_path = \"/opt/ml/processing/model/model.tar.gz\"\n",
    "\n",
    "with tarfile.open(model_path) as tar:\n",
    "    tar.extractall(path=\"..\")\n",
    "\n",
    "model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "\n",
    "test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "df = pd.read_parquet(test_path)\n",
    "\n",
    "y_test = df.iloc[:, 0].to_numpy()\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "X_test = xgboost.DMatrix(df.values)\n",
    "\n",
    "prediction_probabilities = model.predict(X_test)\n",
    "predictions = np.round(prediction_probabilities)\n",
    "\n",
    "precision = precision_score(y_test, predictions, zero_division=1)\n",
    "recall = recall_score(y_test, predictions)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "fpr, tpr, _ = roc_curve(y_test, prediction_probabilities)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "report_dict = {\n",
    "    \"binary_classification_metrics\": {\n",
    "        \"accuracy\": {\"value\": accuracy, \"standard_deviation\": \"NaN\"},\n",
    "        \"balanced_accuracy\": {\"value\": balanced_accuracy, \"standard_deviation\": \"NaN\"},\n",
    "        \"precision\": {\"value\": precision, \"standard_deviation\": \"NaN\"},\n",
    "        \"recall\": {\"value\": recall, \"standard_deviation\": \"NaN\"},\n",
    "        \"confusion_matrix\": {\n",
    "            \"0\": {\"0\": int(conf_matrix[0][0]), \"1\": int(conf_matrix[0][1])},\n",
    "            \"1\": {\"0\": int(conf_matrix[1][0]), \"1\": int(conf_matrix[1][1])},\n",
    "        },\n",
    "        \"receiver_operating_characteristic_curve\": {\n",
    "            \"false_positive_rates\": list(fpr),\n",
    "            \"true_positive_rates\": list(tpr),\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "output_dir = \"/opt/ml/processing/evaluation\"\n",
    "pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "with open(evaluation_path, \"w\") as f:\n",
    "    f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_evaluate_model = ProcessingStep(\n",
    "    name=\"EvaluateModel\",\n",
    "    processor=evaluate_model_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\",\n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://\" + bucket,\n",
    "                    prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"evaluation\",\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    code=evaluate_script,\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
